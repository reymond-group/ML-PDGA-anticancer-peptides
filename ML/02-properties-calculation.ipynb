{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef, f1_score, precision_score, recall_score\n",
    "import random\n",
    "import pickle\n",
    "from rdkit.Chem import rdchem, Lipinski\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolfiles import MolFromFASTA, MolToSmiles, MolFromSmiles\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "folder = \"/data/AIpep/\"\n",
    "import matplotlib.pyplot as plt\n",
    "from Levenshtein import distance as lev_dist\n",
    "from models import Classifier\n",
    "from dataset import Dataset\n",
    "from dataset import collate_fn_no_activity as collate_fn\n",
    "import tmap as tm\n",
    "from map4 import MAP4Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierRNN(\n",
       "  (embedding): Embedding(42, 100)\n",
       "  (rnn): GRU(100, 400, num_layers=2, batch_first=True)\n",
       "  (output_layer): Linear(in_features=400, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 400\n",
    "n_layers = 2\n",
    "epoch = 38\n",
    "\n",
    "filename = folder + \"models/RNN-classifier/em{}_hi{}_la{}_ep{}\".format(n_embedding, n_hidden, n_layers, epoch)\n",
    "\n",
    "model = Classifier.load_from_file(filename)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "else:\n",
    "    device = \"cpu\" \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated_tl_anticancer = pd.read_pickle(folder+\"pickles/Generated-TL-anticancer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated_tl_anticancer[\"prediction\"] = df_generated_tl_anticancer.Sequence.map(lambda x: model.predict_peptide_sequence(x)[:,1][0])\n",
    "df_generated_tl_anticancer[\"isPredActive\"] = df_generated_tl_anticancer[\"prediction\"] > 0.99205756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_generated_tl_anticancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "def make_id(row):\n",
    "    global count_neg\n",
    "    global count_pos\n",
    "    global count\n",
    "    \n",
    "    if row.Set == \"generated-TL-anticancer\":\n",
    "        count += 1\n",
    "        return f\"gen_anticancer_{count}\"\n",
    "    \n",
    "    else:\n",
    "        return row.ID\n",
    "    \n",
    "new_ids = df_all.apply(make_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ID\"] = new_ids\n",
    "df_all = df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(folder+\"pickles/gen_anticancer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11458"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all[df_all[\"isPredActive\"]==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_test = pd.read_pickle(folder+\"pickles/all_sequences_with_NN_prop_helicity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seqNN(seq, dataframe):\n",
    "    best_dist = float(\"inf\")\n",
    "    dists = dataframe[\"Sequence\"].map(lambda seq2 : lev_dist(seq,seq2))\n",
    "    NNi = np.argmin(dists)\n",
    "    best_dist = dists.iloc[NNi]\n",
    "    NN = dataframe[\"Sequence\"].iloc[NNi]\n",
    "    return best_dist, NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a62bece4aea40b7a000237e419af433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c42b7274e134522b2151f4eccd1cad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all[\"dist-NN-Training\"] = df_all[\"Sequence\"].parallel_map(lambda x: find_seqNN(x, df_training_test[df_training_test[\"Set\"]==\"training\"]))\n",
    "df_all[\"dist-NN-Test\"] = df_all[\"Sequence\"].parallel_map(lambda x: find_seqNN(x, df_training_test[df_training_test[\"Set\"]==\"test\"]))\n",
    "df_all[\"dist_Training\"] = df_all[\"dist-NN-Training\"].map(lambda x: x[0])\n",
    "df_all[\"NN_Training\"] = df_all[\"dist-NN-Training\"].map(lambda x: x[1])\n",
    "df_all[\"dist_Test\"] = df_all[\"dist-NN-Test\"].map(lambda x: x[0])\n",
    "df_all[\"NN_Test\"] = df_all[\"dist-NN-Test\"].map(lambda x: x[1])\n",
    "del df_all[\"dist-NN-Training\"]\n",
    "del df_all[\"dist-NN-Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_smiles(seq):\n",
    "    mol = MolFromFASTA(seq, flavor=True, sanitize = True)\n",
    "    smiles = MolToSmiles(mol, isomericSmiles=True)\n",
    "    return smiles\n",
    "\n",
    "MAP4 = MAP4Calculator(dimensions=1024)\n",
    "def calc_map4(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    map4 = MAP4.calculate(mol)\n",
    "    return np.array(map4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483f8838d5474f8f9f58f0cbc6af01cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2bea5ba21943618bef258ba73daae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all[\"SMILES\"] = df_all.Sequence.parallel_map(seq_to_smiles)\n",
    "df_all[\"MAP4\"] = df_all.SMILES.parallel_map(calc_map4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    \"\"\"Estimates the Jaccard distance of two binary arrays based on their hashes.\n",
    "\n",
    "Arguments:\n",
    "  a {numpy.ndarray} -- An array containing hash values.\n",
    "  b {numpy.ndarray} -- An array containing hash values.\n",
    "\n",
    "Returns:\n",
    "  float -- The estimated Jaccard distance.\n",
    "\"\"\"\n",
    "\n",
    "    # The Jaccard distance of Minhashed values is estimated by\n",
    "    return 1.0 - np.float(np.count_nonzero(a == b)) / np.float(len(a))\n",
    "\n",
    "def find_map_seqNN(fp, dataframe):\n",
    "    best_dist = float(\"inf\")\n",
    "    dists = dataframe[\"MAP4\"].map(lambda fp2 : distance(fp,fp2))\n",
    "    NNi = np.argmin(dists)\n",
    "    best_dist = dists.iloc[NNi]\n",
    "    NN = dataframe[\"Sequence\"].iloc[NNi]\n",
    "    return best_dist, NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"length\"] = df_all.Sequence.map(len)\n",
    "df_all = df_all.query(\"length>1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1275972, 544407, 99402, 24531, 748710, 434603...\n",
       "1        [148235, 721103, 99402, 146216, 174963, 374005...\n",
       "2        [148235, 721103, 99402, 146216, 174963, 374005...\n",
       "3        [148235, 175289, 21952, 189861, 229024, 106000...\n",
       "4        [148235, 721103, 99402, 146216, 174963, 374005...\n",
       "                               ...                        \n",
       "30974    [505114, 175289, 40992, 339644, 316612, 144189...\n",
       "30975    [341943, 2852664, 99402, 1327096, 1038221, 434...\n",
       "30976    [505114, 721103, 99402, 2183376, 316612, 21020...\n",
       "30977    [148235, 198071, 99402, 146216, 174963, 374005...\n",
       "30978    [959134, 2852664, 99402, 2183376, 1133508, 434...\n",
       "Name: MAP4, Length: 30978, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"MAP4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df813bf79cb4fd3ae237e332478f60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966c46e629647b99a0595a89a99a477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all[\"map-dist-NN-Training\"] = df_all[\"MAP4\"].parallel_map(lambda x: find_map_seqNN(x, df_training_test[df_training_test[\"Set\"]==\"training\"]))\n",
    "df_all[\"map-dist-NN-Test\"] = df_all[\"MAP4\"].parallel_map(lambda x: find_map_seqNN(x, df_training_test[df_training_test[\"Set\"]==\"test\"]))\n",
    "df_all[\"map_dist_Training\"] = df_all[\"map-dist-NN-Training\"].map(lambda x: x[0])\n",
    "df_all[\"map_NN_Training\"] = df_all[\"map-dist-NN-Training\"].map(lambda x: x[1])\n",
    "df_all[\"map_dist_Test\"] = df_all[\"map-dist-NN-Test\"].map(lambda x: x[0])\n",
    "df_all[\"map_NN_Test\"] = df_all[\"map-dist-NN-Test\"].map(lambda x: x[1])\n",
    "del df_all[\"map-dist-NN-Training\"]\n",
    "del df_all[\"map-dist-NN-Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(folder+\"pickles/gen_anticancer_with_NN.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_neg(seq):\n",
    "    seq = seq.upper()\n",
    "    neg = (seq.count('D') + seq.count('E'))\n",
    "    return neg\n",
    "\n",
    "def calc_pos(seq):\n",
    "    seq = seq.upper()\n",
    "    pos = (seq.count('K') + seq.count('R'))\n",
    "    return pos\n",
    "\n",
    "def calc_aa(seq, aa):\n",
    "    seq = seq.upper()\n",
    "    aa_f = seq.count(aa)/len(seq) \n",
    "    return aa_f\n",
    "\n",
    "def calc_hac(smiles):\n",
    "    mol = MolFromSmiles(smiles)\n",
    "    hac = Lipinski.HeavyAtomCount(mol)\n",
    "    return hac\n",
    "\n",
    "def calc_hydr(seq):\n",
    "    hydr = (seq.count('A') + seq.count('L') + seq.count('I') + seq.count('L') \\\n",
    "            + seq.count('V') + seq.count('M') + seq.count('F') + seq.count('C'))\n",
    "    return hydr\n",
    "\n",
    "def hydropatch(seq):\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    hydro = [\"A\", \"L\", \"I\", \"V\", \"M\", \"F\", \"C\"]\n",
    "    patch = \"\"\n",
    "    patches = []\n",
    "    for aa in seq:\n",
    "        if aa in hydro:\n",
    "            patch+=aa\n",
    "        else:\n",
    "            if patch != \"\":\n",
    "                patches.append(len(patch))\n",
    "            patch=\"\"\n",
    "    if patch != \"\":\n",
    "        patches.append(len(patch))    \n",
    "    return np.array(patches)\n",
    "\n",
    "\n",
    "def calc_hba(smiles):\n",
    "    mol = MolFromSmiles(smiles)\n",
    "    hba = Lipinski.NumHAcceptors(mol)\n",
    "    return hba\n",
    "\n",
    "def calc_hbd(smiles):\n",
    "    mol = MolFromSmiles(smiles)\n",
    "    hbd = Lipinski.NumHDonors(mol)\n",
    "    return hbd\n",
    "\n",
    "def mean(patches):\n",
    "    if len(patches) == 0:\n",
    "        return 0\n",
    "    return round(patches.mean(),2)\n",
    "\n",
    "d_aminoacids = [\"a\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"l\",\"m\",\"n\",\"p\",\"k\",\"q\",\"r\",\"s\",\"t\",\"v\",\"w\",\"y\"]\n",
    "def d_aa(seq):\n",
    "    for aa in d_aminoacids:\n",
    "        if aa in seq:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"D_AA\"] = df_all.Sequence.map(d_aa) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminoacids = [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"L\",\"M\",\"N\",\"P\",\"K\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"Y\"]\n",
    "for aa in aminoacids:\n",
    "    df_all[f\"{aa}_fract\"] = df_all.Sequence.map(lambda x: calc_aa(x, aa))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54db35ad025464da35ad82d208687d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b394b94b620418ba1191464a051635c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0220d3d8e9457c8896a60ea59fd16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87484a17fb1c46ac918638b737981bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6754787396e24a8087b3d23f661b799e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d19c3646be4541a543486431660195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4622983f734454bec86e01a20301e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3873), Label(value='0 / 3873'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all[\"positive\"] = df_all.Sequence.parallel_map(calc_pos)\n",
    "df_all[\"negative\"] = df_all.Sequence.parallel_map(calc_neg)\n",
    "df_all[\"HAC\"] = df_all.SMILES.parallel_map(calc_hac)\n",
    "df_all[\"HBA\"] = df_all.SMILES.parallel_map(calc_hba)\n",
    "df_all[\"HBD\"] = df_all.SMILES.parallel_map(calc_hbd)\n",
    "df_all[\"hydrophobic\"] = df_all.Sequence.parallel_map(calc_hydr)\n",
    "df_all[\"hydrophobic_patches\"] = df_all.Sequence.parallel_map(hydropatch)\n",
    "df_all[\"hydrophobic_patches_num\"] = df_all.hydrophobic_patches.map(len)\n",
    "df_all[\"hydrophobic_patches_len\"] = df_all.hydrophobic_patches.map(mean)\n",
    "df_all[\"hydro_res_fract\"] = df_all.apply(lambda x: x.hydrophobic / x.length, axis=1)\n",
    "df_all[\"pos_res_fract\"] = df_all.apply(lambda x: x.positive / x.length, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More properties (Hydrophobic moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Calculates a set of properties from a protein sequence:\n",
    "    - hydrophobicity (according to a particular scale)\n",
    "    - mean hydrophobic dipole moment assuming it is an alpha-helix.\n",
    "    - total charge (at pH 7.4)\n",
    "    - amino acid composition\n",
    "    - discimination factor according to Rob Keller (IJMS, 2011)\n",
    "Essentially the same as HeliQuest (reproduces the same values).\n",
    "Author:\n",
    "  Joao Rodrigues\n",
    "  j.p.g.l.m.rodrigues@gmail.com\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "#\n",
    "# Definitions\n",
    "#\n",
    "scales = {'Fauchere-Pliska': {'A':  0.31, 'R': -1.01, 'N': -0.60,\n",
    "                              'D': -0.77, 'C':  1.54, 'Q': -0.22,\n",
    "                              'E': -0.64, 'G':  0.00, 'H':  0.13,\n",
    "                              'I':  1.80, 'L':  1.70, 'K': -0.99,\n",
    "                              'M':  1.23, 'F':  1.79, 'P':  0.72,\n",
    "                              'S': -0.04, 'T':  0.26, 'W':  2.25,\n",
    "                              'Y':  0.96, 'V':  1.22},\n",
    "\n",
    "          'Eisenberg': {'A':  0.25, 'R': -1.80, 'N': -0.64,\n",
    "                        'D': -0.72, 'C':  0.04, 'Q': -0.69,\n",
    "                        'E': -0.62, 'G':  0.16, 'H': -0.40,\n",
    "                        'I':  0.73, 'L':  0.53, 'K': -1.10,\n",
    "                        'M':  0.26, 'F':  0.61, 'P': -0.07,\n",
    "                        'S': -0.26, 'T': -0.18, 'W':  0.37,\n",
    "                        'Y':  0.02, 'V':  0.54},\n",
    "          }\n",
    "_supported_scales = list(scales.keys())\n",
    "\n",
    "aa_charge = {'E': -1, 'D': -1, 'K': 1, 'R': 1}\n",
    "\n",
    "#\n",
    "# Functions\n",
    "#\n",
    "def assign_hydrophobicity(sequence, scale='Fauchere-Pliska'):  # noqa: E302\n",
    "    \"\"\"Assigns a hydrophobicity value to each amino acid in the sequence\"\"\"\n",
    "\n",
    "    hscale = scales.get(scale, None)\n",
    "    if not hscale:\n",
    "        raise KeyError('{} is not a supported scale. '.format(scale))\n",
    "\n",
    "    hvalues = []\n",
    "    for aa in sequence:\n",
    "        sc_hydrophobicity = hscale.get(aa, None)\n",
    "        if sc_hydrophobicity is None:\n",
    "            raise KeyError('Amino acid not defined in scale: {}'.format(aa))\n",
    "        hvalues.append(sc_hydrophobicity)\n",
    "\n",
    "    return hvalues\n",
    "\n",
    "\n",
    "def calculate_moment(array, angle=100):\n",
    "    \"\"\"Calculates the hydrophobic dipole moment from an array of hydrophobicity\n",
    "    values. Formula defined by Eisenberg, 1982 (Nature). Returns the average\n",
    "    moment (normalized by sequence length)\n",
    "    uH = sqrt(sum(Hi cos(i*d))**2 + sum(Hi sin(i*d))**2),\n",
    "    where i is the amino acid index and d (delta) is an angular value in\n",
    "    degrees (100 for alpha-helix, 180 for beta-sheet).\n",
    "    \"\"\"\n",
    "\n",
    "    sum_cos, sum_sin = 0.0, 0.0\n",
    "    for i, hv in enumerate(array):\n",
    "        rad_inc = ((i*angle)*math.pi)/180.0\n",
    "        sum_cos += hv * math.cos(rad_inc)\n",
    "        sum_sin += hv * math.sin(rad_inc)\n",
    "    if len(array) != 0:\n",
    "        return math.sqrt(sum_cos**2 + sum_sin**2) / len(array)\n",
    "    else:\n",
    "        print(array)\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calculate_charge(sequence, charge_dict=aa_charge):\n",
    "    \"\"\"Calculates the charge of the peptide sequence at pH 7.4\n",
    "    \"\"\"\n",
    "    sc_charges = [charge_dict.get(aa, 0) for aa in sequence]\n",
    "    return sum(sc_charges)\n",
    "\n",
    "\n",
    "def calculate_discrimination(mean_uH, total_charge):\n",
    "    \"\"\"Returns a discrimination factor according to Rob Keller (IJMS, 2011)\n",
    "    A sequence with d>0.68 can be considered a potential lipid-binding region.\n",
    "    \"\"\"\n",
    "    d = 0.944*mean_uH + 0.33*total_charge\n",
    "    return d\n",
    "\n",
    "\n",
    "def calculate_composition(sequence):\n",
    "    \"\"\"Returns a dictionary with percentages per classes\"\"\"\n",
    "\n",
    "    # Residue character table\n",
    "    polar_aa = set(('S', 'T', 'N', 'H', 'Q', 'G'))\n",
    "    speci_aa = set(('P', 'C'))\n",
    "    apolar_aa = set(('A', 'L', 'V', 'I', 'M'))\n",
    "    charged_aa = set(('E', 'D', 'K', 'R'))\n",
    "    aromatic_aa = set(('W', 'Y', 'F'))\n",
    "\n",
    "    n_p, n_s, n_a, n_ar, n_c = 0, 0, 0, 0, 0\n",
    "    for aa in sequence:\n",
    "        if aa in polar_aa:\n",
    "            n_p += 1\n",
    "        elif aa in speci_aa:\n",
    "            n_s += 1\n",
    "        elif aa in apolar_aa:\n",
    "            n_a += 1\n",
    "        elif aa in charged_aa:\n",
    "            n_c += 1\n",
    "        elif aa in aromatic_aa:\n",
    "            n_ar += 1\n",
    "\n",
    "    return {'polar': n_p, 'special': n_s,\n",
    "            'apolar': n_a, 'charged': n_c, 'aromatic': n_ar}\n",
    "\n",
    "\n",
    "def analyze_sequence(name=None, sequence=None, window=18, verbose=False):\n",
    "    \"\"\"Runs all the above on a sequence. Pretty prints the results\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    w = window\n",
    "\n",
    "    outdata = []  # for csv writing\n",
    "\n",
    "    # Processing...\n",
    "    seq_len = len(sequence)\n",
    "    print('[+] Analysing sequence {} ({} aa.)'.format(name, seq_len))\n",
    "    print('[+] Using a window of {} aa.'.format(w))\n",
    "    for seq_range in range(0, seq_len):\n",
    "\n",
    "        seq_w = sequence[seq_range:seq_range+w]\n",
    "        if seq_range and len(seq_w) < w:\n",
    "            break\n",
    "\n",
    "        # Numerical values\n",
    "        z = calculate_charge(seq_w)\n",
    "        seq_h = assign_hydrophobicity(seq_w)\n",
    "        av_h = sum(seq_h)/len(seq_h)\n",
    "        av_uH = calculate_moment(seq_h)\n",
    "        d = calculate_discrimination(av_uH, z)\n",
    "\n",
    "        # AA composition\n",
    "        aa_comp = calculate_composition(seq_w)\n",
    "        n_tot_pol = aa_comp['polar'] + aa_comp['charged']\n",
    "        n_tot_apol = aa_comp['apolar'] + aa_comp['aromatic'] + aa_comp['special']  # noqa: E501\n",
    "        n_charged = aa_comp['charged']  # noqa: E501\n",
    "        n_aromatic = aa_comp['aromatic']  # noqa: E501\n",
    "\n",
    "        _t = [name, sequence, seq_range+1, w, seq_w, z, av_h, av_uH, d,\n",
    "              n_tot_pol, n_tot_apol, n_charged, n_aromatic]\n",
    "        outdata.append(_t)\n",
    "\n",
    "        if verbose:\n",
    "            print('  Window {}: {}-{}-{}'.format(seq_range+1, seq_range,\n",
    "                                                 seq_w, seq_range+w))\n",
    "            print('    z={:<3d} <H>={:4.3f} <uH>={:4.3f} D={:4.3f}'.format(z, av_h,  # noqa: E501\n",
    "                                                                           av_uH, d))  # noqa: E501\n",
    "            print('    Amino acid composition')\n",
    "            print('      Polar    : {:3d} / {:3.2f}%'.format(n_tot_pol, n_tot_pol*100/w))  # noqa: E501\n",
    "            print('      Non-Polar: {:3d} / {:3.2f}%'.format(n_tot_apol, n_tot_apol*100/w))  # noqa: E501\n",
    "            print('      Charged  : {:3d} / {:3.2f}%'.format(n_charged, n_charged*100/w))  # noqa: E501\n",
    "            print('      Aromatic : {:3d} / {:3.2f}%'.format(n_aromatic, n_aromatic*100/w))  # noqa: E501\n",
    "            print()\n",
    "\n",
    "    return outdata\n",
    "\n",
    "\n",
    "def read_fasta_file(afile):\n",
    "    \"\"\"Parses a file with FASTA formatted sequences\"\"\"\n",
    "\n",
    "    if not os.path.isfile(afile):\n",
    "        raise IOError('File not found/readable: {}'.format(afile))\n",
    "\n",
    "    sequences = []\n",
    "    seq_name, cur_seq = None, None\n",
    "    with open(afile) as handle:\n",
    "        for line in handle:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if cur_seq:\n",
    "                    sequences.append((seq_name, ''.join(cur_seq)))\n",
    "                seq_name = line[1:]\n",
    "                cur_seq = []\n",
    "            elif line:\n",
    "                cur_seq.append(line)\n",
    "    sequences.append((seq_name, ''.join(cur_seq)))  # last seq\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def hydr_moment(seq):\n",
    "    seq = seq.upper()\n",
    "    hdr = assign_hydrophobicity(seq,\"Eisenberg\")\n",
    "    return calculate_moment(hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"HydroMoment\"] = df_all.Sequence.map(hydr_moment)\n",
    "df_all[\"charge\"] = df_all[\"Sequence\"].map(lambda x: calculate_charge(x.upper()))\n",
    "df_all[\"hydrophobicity\"] = df_all[\"Sequence\"].map(lambda x: assign_hydrophobicity(x.upper()))\n",
    "df_all[\"av_hydrophobicity\"] = df_all[\"hydrophobicity\"].map(lambda x: sum(x)/len(x)) \n",
    "df_all[\"discrimination\"] = df_all.apply(lambda x: calculate_discrimination(x.HydroMoment, x.charge), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(folder+\"pickles/gen_anticancer_with_NN_prop.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPIDER helicity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_fasta(row):\n",
    "    seq = row[\"Sequence\"]\n",
    "    ID = row[\"Sequence\"]\n",
    "    l = 40\n",
    "    fasta_seq = seq\n",
    "    fasta = \">{}\\n{}\".format(ID,fasta_seq)\n",
    "    return fasta\n",
    "\n",
    "def fastafile(row, folder=\"/data/AIpep/spiderData_anticancer/\"):\n",
    "    fasta = row[\"fasta\"]\n",
    "    fasta = fasta.upper()\n",
    "    ID = str(row[\"ID\"])\n",
    "    name = folder+ID+\".seq\"\n",
    "    with open(name, \"w\") as output:\n",
    "        output.write(fasta)\n",
    "        \n",
    "def filename(row, folder=\"/data/AIpep/spiderData_anticancer/\"):\n",
    "    ID = str(row[\"ID\"])\n",
    "    name = ID+\".seq\"\n",
    "    return name\n",
    "\n",
    "def fileloc(row, folder=\"/data/AIpep/spiderData_anticancer/\"):\n",
    "    ID = str(row[\"ID\"])\n",
    "    name = folder+ID+\".seq\"\n",
    "    return name\n",
    "\n",
    "def read_spider(row, folder=\"/data/AIpep/spider3_anticancer/\"):\n",
    "    ss = []\n",
    "    ID = str(row[\"ID\"])\n",
    "    name = ID+\".seq.i2\"\n",
    "\n",
    "    with open(folder+name) as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            line = line.split(\" \")\n",
    "            ss.append(line[2])\n",
    "    return ss[1:]\n",
    "\n",
    "def count_ss(ss, pred = \"H\"):\n",
    "    return ss.count(pred)\n",
    "def fract_ss(ss, pred = \"H\"):\n",
    "    if len(ss)!=0:\n",
    "        return ss.count(pred)/len(ss)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"fasta\"] = df_all.apply(row_to_fasta, axis = 1)\n",
    "df_all.apply(fastafile, axis=1)\n",
    "df_all[\"SpiderFilename\"] = df_all.apply(filename, axis=1)\n",
    "df_all[\"SpiderFileloc\"] = df_all.apply(fileloc, axis=1)\n",
    "df_all[[\"SpiderFilename\", \"SpiderFileloc\"]].to_csv(\"../SPIDER3-Single_np/file_list_anticancer\", header=False, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SPIDER\n",
    "%%bash\n",
    "conda activate aipep\n",
    "./SPIDER3-Single_np/impute_script_np.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"SS\"] = df_all.apply(read_spider, axis=1)\n",
    "df_all[\"countH\"] = df_all.SS.map(count_ss)\n",
    "df_all[\"fraction_PredHelical\"] = df_all.SS.map(fract_ss)\n",
    "df_all[\"fraction_PredBetaSheet\"] = df_all.SS.map(lambda x : fract_ss(x, \"E\"))\n",
    "df_all[\"fraction_PredCoil\"] = df_all.SS.map(lambda x : fract_ss(x, \"C\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(folder+\"pickles/gen_anticancer_with_NN_prop_helicity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
